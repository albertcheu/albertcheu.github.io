---
layout: page
title: Research
permalink: /research/
---

I am a PhD. student at Northeastern University in the College of Computer and Information Science. My advisor is Jonathan Ullman.

I currently work on differential privacy. We'd like to evaluate functions on personal data but reporting the exact value reveals information about the contributors: as a toy example, if Eve knows Bob does not have cancer and is also told either Bob or Alice has cancer, she can deduce that Alice has cancer. Roughly speaking, the game is to add randomness to aggregate statistics in order to create "plausible deniability" about any individual's data, while keeping the statistics reasonably accurate.

Here are my papers on this subject:

1. [Distributed Differential Privacy via Shuffling](https://arxiv.org/abs/1808.01394), presented at [Eurocrypt 2019](https://eurocrypt.iacr.org/2019/).

2. [Manipulation Attacks agaisnt Local Differential Privacy](https://arxiv.org/abs/1909.09630), presented at [Theory and Practice of Differential Privacy 2019](https://tpdp.cse.buffalo.edu/2019/).

3. [Separating Local & Shuffled Differential Privacy via Histograms](http://arxiv.org/abs/1911.06879), to be presented at [Information Theoretic Cryptography 2020](https://itcrypto.github.io/2020.html).

4. [Connecting Robust Shuffle Privacy and Pan-Privacy](https://arxiv.org/abs/2004.09481).